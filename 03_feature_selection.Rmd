---
title: "Feature selection"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, eval = FALSE)
```

```{r, echo=FALSE}
library(caret)
set.seed(10)
```
## Recursive feature elimination (RFE)

Features were primarily chosen by examining the literature. However, as feature selection is a significant part of statistical learning, RFE analysis was used to examine the features used to train the rSVM model.

```{r}
svmProfile <- rfe(features[,2:45],
                  features[,46],
                  rfeControl = rfeControl(functions = caretFuncs,method = "repeatedcv", number = 10, repeats = 3),
                  method = "svmRadial",
                  preProcess = c("center", "scale"))
```

```{r, echo=FALSE}
# use small subset of data to test
# 
# svmProfile <- rfe(features[c(1:25,6925:6950),2:45], 
#                   features[c(1:25,6925:6950),46],
#                   rfeControl = rfeControl(functions = caretFuncs, method = "repeatedcv", number = 10, repeats = 3),
#                   method = "svmRadial",
#                   preProcess = c("center", "scale"))
```

Read RFE results (obtained from code block above which was run on an HPC)

```{r}
svmProfile <- readRDS("cache/rfe.rds")
```

Rank important features
```{r}
varImp(svmProfile)
```

